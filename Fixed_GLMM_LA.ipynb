{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Laplace approximation on GLMM w/ full parameter space estimated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import norm\n",
    "from scipy.linalg import block_diag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All inputs follows structure: [$x$, $y$, $\\mu$, $\\beta$, $\\tau$]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-Sum_exp trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    c = max(x)\n",
    "    LSE = c + np.log(np.sum(np.exp(x - c)))\n",
    "    return np.exp(x - LSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $\\pi_{ij}$:\n",
    "\n",
    "$$\\pi_{ij} = \\dfrac{\\exp{(X_{ij}^\\top\\beta}+\\tau_{i}\\mu_{i})}{1 + \\exp{(X_{ij}^\\top\\beta}+\\tau_{i}\\mu_{i})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pi(x, y, mu, beta, tau):\n",
    "    result = np.asarray((np.exp(x @ beta + tau * mu) / (1 + np.exp(x @ beta + tau * mu))))\n",
    "    # Check if there are exp(0) cases, if true, return \\pi = 1 correspondingly\n",
    "    return np.nan_to_num(result, nan = 1)\n",
    "\n",
    "#     if np.exp(x @ beta + mu).max() == np.inf:\n",
    "#         return np.nan_to_num(result, nan = 1)\n",
    "#     else:\n",
    "#         return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g(\\mu_{i})$:\n",
    "\n",
    "$$g(\\mu_{i};\\beta)=\\sum_{j=1}^{n_i}\\left[y_{ij}\\log\\pi_{ij}+(1-y_{ij})\\log(1-\\pi_{ij})\\right]+\\log[\\tau_{i}\\phi(\\mu_{i},1)]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x, y, mu, beta, tau):\n",
    "    g = sum(y * logsumexp(Pi(x, y, mu, beta, tau)) + (1 - y) * logsumexp(1 - Pi(x, y, mu, beta, tau))) \\\n",
    "    + np.nan_to_num(np.log(tau * (np.sqrt(2 * np.pi))**(-1) * np.exp(-mu**2/2)), nan=0)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_\\mu(\\mu_{i})$:\n",
    "\n",
    "$$\\dfrac{\\partial g}{\\partial \\mu_{i}}=\\sum_{j=1}^{n_i}\\tau_{i}(y_{ij}-\\pi_{ij})-\\mu_{i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_u(x, y, mu, beta, tau):\n",
    "    return tau * sum((y - Pi(x, y, mu, beta, tau))) - mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_\\beta(\\beta)$:\n",
    "\n",
    "$$\\dfrac{\\partial g}{\\partial \\beta}=\\sum_{j=1}^{n_i}X_{ij}(y_{ij}-\\pi_{ij})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_b(x, y, mu, beta, tau):\n",
    "    return np.sum(x * y - x * Pi(x, y, mu, beta, tau), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_\\tau(\\tau_{i})$:\n",
    "\n",
    "$$\\dfrac{\\partial g}{\\partial \\tau_{i}}=\\sum_{j=1}^{n_i}\\mu_{i}(y_{ij}-\\pi_{ij})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_t(x, y, mu, beta, tau):\n",
    "    return mu * sum((y - Pi(x, y, mu, beta, tau)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Second derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\mu}(\\mu_{i})$:\n",
    "\n",
    "$$\\dfrac{\\partial^2 g}{\\partial \\mu_{i}^2}=-\\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial\\pi_{ij}}{\\partial\\mu_{i}}-1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_uu(x, y, mu, beta, tau):\n",
    "    result = np.nan_to_num(tau * np.asarray((np.exp(x @ beta + tau * mu) /\\\n",
    "                                              (1 + np.exp(x @ beta + tau * mu))**2)), nan = 0)\n",
    "    return - tau * sum(result) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\beta\\beta}(\\beta)$:\n",
    "\n",
    "$$\\dfrac{\\partial^2 g}{\\partial \\beta^2}=-\\sum_{j=1}^{n_i}X_{ij}\\dfrac{\\partial\\pi_{ij}}{\\partial\\beta}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_bb(x, y, mu, beta, tau):\n",
    "    result = 0\n",
    "    for i in range(len(y)):\n",
    "        result += -np.asarray(x[i].reshape(x.shape[1],1) @ x[i].reshape(1,x.shape[1])\\\n",
    "        * np.nan_to_num((np.exp(x[i] @ beta + tau * mu) / (1 + np.exp(x[i] @ beta + tau * tau * mu))**2), nan = 0))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\tau\\tau}(\\tau_{i})$:\n",
    "\n",
    "$$\\dfrac{\\partial^2 g}{\\partial \\tau_i^2}=-\\mu_i\\sum_{j=1}^{n_i}\\dfrac{\\partial\\pi_{ij}}{\\partial\\tau_{i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_tt(x, y, mu, beta, tau):\n",
    "    result = np.nan_to_num(mu * np.asarray((np.exp(x @ beta + tau * mu) /\\\n",
    "                                              (1 + np.exp(x @ beta + tau * mu))**2)), nan = 0)\n",
    "    return -mu * sum(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\beta}(\\beta)$:\n",
    "\n",
    "$$\\dfrac{\\partial^2 g}{\\partial \\mu_{i}\\partial \\beta}=-\\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial\\pi_{ij}}{\\partial\\beta}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_ub(x, y, mu, beta, tau):\n",
    "    result = np.nan_to_num(np.asarray((np.exp(x @ beta + tau * mu) /\\\n",
    "                                       (1 + np.exp(x @ beta + tau * mu))**2)), nan = 0)\n",
    "    return -tau * np.sum(x * result, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\tau}(\\tau_i)$:\n",
    "\n",
    "$$\\dfrac{\\partial^2 g}{\\partial\\mu_i\\partial\\tau_i}=\\sum_{j=1}^{n_i}\\left(y_{ij}-\\pi_{ij}\\right)-\\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial\\pi_{ij}}{\\partial\\tau_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_ut(x, y, mu, beta, tau):\n",
    "    result = sum(y - Pi(x, y, mu, beta, tau))\\\n",
    "    - tau * sum(mu * np.nan_to_num(mu * np.asarray((np.exp(x @ beta + tau * mu) /\\\n",
    "                                          (1 + np.exp(x @ beta + tau * mu))**2)), nan = 0))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\beta\\tau}(\\beta,\\tau)$:\n",
    "\n",
    "$$\\dfrac{\\partial^2 g}{\\partial \\beta\\partial \\tau_i}=-\\sum_{j=1}^{n_i}X_{ij}\\dfrac{\\partial\\pi_{ij}}{\\partial\\tau_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_bt(x, y, mu, beta, tau):\n",
    "    result = np.nan_to_num(mu * np.asarray((np.exp(x @ beta + tau * mu) /\\\n",
    "                                          (1 + np.exp(x @ beta + tau * mu))**2)), nan = 0)\n",
    "    return -np.sum(x * result, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Third derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\mu\\mu}(\\hat\\mu_i,\\beta)$:\n",
    "\n",
    "$$\\dfrac{\\partial^3 g}{\\partial \\mu_{i}^3} = -\\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial^2\\pi_{ij}}{\\partial\\mu_{i}^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_uuu(x, y, mu, beta, tau):\n",
    "    return -tau * sum(-tau**2 * np.nan_to_num(np.asarray((np.exp(x @ beta + tau * mu) * (np.exp(x @ beta + tau * mu) - 1)\\\n",
    "                             / (1 + np.exp(x @ beta + tau * mu))**3)), nan = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\mu\\beta}(\\hat\\mu_{i},\\beta)$:\n",
    "\n",
    "$$\\dfrac{\\partial^3 g}{\\partial \\mu_{i}^2\\partial \\beta} = -\\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial^2\\pi_{ij}}{\\partial\\mu_{i}\\partial\\beta}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_uub(x, y, mu, beta, tau): # add -\n",
    "    return -tau * np.sum(-tau * x * np.nan_to_num(np.asarray((np.exp(x @ beta + tau * mu) * (np.exp(x @ beta + tau * mu) - 1)\\\n",
    "                             / (1 + np.exp(x @ beta + tau * mu))**3)), nan = 0), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\beta\\beta}(\\hat\\mu_{i},\\beta)$:\n",
    "\n",
    "$$\\dfrac{\\partial^3 g}{\\partial \\mu_{i}\\partial \\beta^2}=-\\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial^2\\pi_{ij}}{\\partial\\beta^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_ubb(x, y, mu, beta, tau):\n",
    "    result = 0\n",
    "    for i in range(len(y)):\n",
    "        result += -np.asarray(x[i].reshape(x.shape[1],1) @ x[i].reshape(1,x.shape[1])\\\n",
    "                         * np.nan_to_num((np.exp(x[i] @ beta + tau * mu) * (np.exp(x[i] @ beta + tau * mu) - 1)\\\n",
    "                                       / (1 + np.exp(x[i] @ beta + tau * mu))**3), nan = 0))\n",
    "    return -tau * result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\mu\\tau}(\\hat\\mu_{i},\\beta)$:\n",
    "\n",
    "$$\\dfrac{\\partial^3 g}{\\partial \\mu_{i}^2\\partial \\tau_i} = -\\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial^2\\pi_{ij}}{\\partial\\mu_{i}\\partial\\tau_i}-\\sum_{j=1}^{n_i}\\dfrac{\\partial\\pi_{ij}}{\\partial\\mu_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_uut(x, y, mu, beta, tau):\n",
    "    result = -tau * np.sum(np.nan_to_num((np.exp(x @ beta + tau * mu) * ((1 - tau * mu) * np.exp(x @ beta + tau * mu) + tau * mu + 1))\\\n",
    "    / (1 + np.exp(x @ beta + tau * mu))**3, nan = 0), axis = 0) - np.sum(np.nan_to_num(tau * np.asarray((np.exp(x @ beta + tau * mu) /\\\n",
    "                                              (1 + np.exp(x @ beta + tau * mu))**2)), nan = 0))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\tau\\tau}(\\hat\\mu_{i},\\beta)$:\n",
    "\n",
    "$$\\dfrac{\\partial^3 g}{\\partial \\mu_{i}\\partial \\tau_i^2} = -2\\sum_{j=1}^{n_i}\\dfrac{\\partial\\pi_{ij}}{\\partial\\tau_i}-\\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial^2\\pi_{ij}}{\\partial\\tau_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_utt(x, y, mu, beta, tau):\n",
    "    result = -2 * np.sum(np.nan_to_num(mu * np.asarray((np.exp(x @ beta + tau * mu) /\\\n",
    "                                          (1 + np.exp(x @ beta + tau * mu))**2)), nan = 0), axis = 0)\\\n",
    "    - tau * np.sum( np.nan_to_num(-mu**2 * np.exp(x @ beta + tau * mu) * (np.exp(x @ beta + tau * mu) - 1) /\\\n",
    "                   (1 + np.exp(x @ beta + tau * mu))**3, nan = 0) )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\beta\\tau_{i}}(\\hat\\mu_{i},\\beta, \\tau_i)$:\n",
    "\n",
    "$$\n",
    "\\dfrac{\\partial^3 g}{\\partial \\mu_{i}\\partial \\beta\\partial\\tau_i}=-\\sum_{j=1}^{n_i}\\dfrac{\\partial\\pi_{ij}}{\\partial\\beta} - \\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial^2\\pi_{ij}}{\\partial\\beta\\partial\\tau_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_ubt(x, y, mu, beta, tau):\n",
    "    left = np.nan_to_num(np.asarray((np.exp(x @ beta + tau * mu) /\\\n",
    "                                       (1 + np.exp(x @ beta + tau * mu))**2)), nan = 0)\n",
    "    left = -np.sum(x * left, axis = 0)\n",
    "    right = np.nan_to_num(np.asarray((mu * np.exp(x @ beta + tau * mu) * (np.exp(x @ beta + tau * mu) - 1))/\\\n",
    "                                    (np.exp(x @ beta + tau * mu) + 1)**3), nan = 0)\n",
    "    right = -np.sum(x * right, axis = 0)\n",
    "    return left + right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Forth derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\mu\\mu\\mu}(\\hat\\mu_{i},\\beta_0)$:\n",
    "\n",
    "$$g_{\\mu\\mu\\mu\\mu}(\\hat\\mu_{i},\\beta) = -\\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial^3\\pi_{ij}}{\\partial\\mu_{i}^3}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_uuuu(x, y, mu, beta, tau):\n",
    "    result = -tau * np.sum( np.nan_to_num(-tau**3 * np.exp(2 * x @ beta + 2 * tau * mu)/(np.exp(x @ beta + tau * mu) + 1)**3\\\n",
    "                           - tau**3 * np.exp(x @ beta + tau * mu) * (np.exp(x @ beta + tau * mu) - 1)/(np.exp(x @ beta + tau * mu) + 1)**3\\\n",
    "                           + 3 * tau**3 * np.exp(2 * x @ beta + 2 * tau * mu) * (np.exp(x @ beta + tau * mu) - 1)/(np.exp(x @ beta + tau * mu) + 1)**4, nan = 0) )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def g_uuuu(x, y, mu, beta, tau):\n",
    "#     result = sum(- np.nan_to_num((np.exp(x @ beta + tau * mu) * (np.exp(x @ beta + tau * mu) - 1) \\\n",
    "#                                   / (1 + np.exp(x @ beta + tau * mu)) ** 3), nan=0) \\\n",
    "#                  + np.nan_to_num((3 * np.exp(2 * (x @ beta + tau * mu)) * (np.exp(x @ beta + tau * mu) - 1) \\\n",
    "#                                   / (1 + np.exp(x @ beta + tau * mu)) ** 4), nan=0) \\\n",
    "#                  - np.nan_to_num((np.exp(2 * (x @ beta + tau * mu)) / (1 + np.exp(x @ beta + tau * mu)) ** 3), nan=0) \\\n",
    "#                  )\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\mu\\mu\\beta}(\\hat\\mu_{i},\\beta)$:\n",
    "\n",
    "$$g_{\\mu\\mu\\mu\\beta}(\\hat\\mu_{i},\\beta) = -\\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial^3\\pi_{ij}}{\\partial\\mu_{i}^2\\partial\\beta}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_uuub(x, y, mu, beta, tau):\n",
    "    result = -tau * np.sum( np.nan_to_num(tau**2 * x * np.exp(x @ beta + tau * mu)\\\n",
    "                           * (-4 * np.exp(x @ beta + tau * mu) + np.exp(2 * x @ beta + 2 * tau * mu) + 1)\\\n",
    "                           /(np.exp(x @ beta + tau * mu) + 1)**4, nan = 0), axis = 0 )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def g_uuub(x, y, mu, beta, tau):\n",
    "#     result = tau * np.sum(- x * np.asarray(np.nan_to_num((np.exp(x @ beta + tau * mu) * (np.exp(x @ beta + tau * mu) - 1) \\\n",
    "#                                                     / (1 + np.exp(x @ beta + tau * mu)) ** 3), nan=0) \\\n",
    "#                                      + np.nan_to_num(\n",
    "#         (3 * np.exp(2 * (x @ beta + tau * mu)) * (np.exp(x @ beta + tau * mu) - 1) \\\n",
    "#          / (1 + np.exp(x @ beta + tau * mu)) ** 4), nan=0) \\\n",
    "#                                      - np.nan_to_num(\n",
    "#         (np.exp(2 * (x @ beta + tau * mu)) / (1 + np.exp(x @ beta + tau * mu)) ** 3), nan=0))\n",
    "#                     , axis=0)\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\mu\\beta\\beta}(\\hat\\mu_{i},\\beta)$:\n",
    "\n",
    "$$g_{\\mu\\mu\\beta\\beta}(\\hat\\mu_{i},\\beta) = -\\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial^3\\pi_{ij}}{\\partial\\mu_{i}\\partial\\beta^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_uubb(x, y, mu, beta, tau):\n",
    "    result = 0\n",
    "    for i in range(len(y)):\n",
    "        result += x[i].reshape(x.shape[1],1) @ x[i].reshape(1,x.shape[1]) * np.nan_to_num(np.exp(x[i] @ beta + tau * mu)\\\n",
    "        * (-4 * np.exp(x[i] @ beta + tau * mu) + np.exp(2 * x[i] @ beta + 2 * tau * mu) + 1)\\\n",
    "        / (np.exp(x[i] @ beta + tau * mu) + 1)**4, nan=0)\n",
    "        \n",
    "    result *= tau                     \n",
    "        \n",
    "    return -tau * result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\mu\\mu\\tau}(\\hat\\mu_{i},\\beta)$:\n",
    "\n",
    "$$g_{\\mu\\mu\\mu\\tau}(\\hat\\mu_{i},\\beta) = -\\sum_{j=1}^{n_i}\\dfrac{\\partial^2\\pi_{ij}}{\\partial\\mu_i^2} -\\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial^3\\pi_{ij}}{\\partial\\mu_{i}^2\\partial\\tau_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_uuut(x, y, mu, beta, tau):\n",
    "    left = -np.sum(-tau**2 * np.nan_to_num(np.asarray((np.exp(x @ beta + tau * mu) * (np.exp(x @ beta + tau * mu) - 1)\\\n",
    "                             / (1 + np.exp(x @ beta + tau * mu))**3)), nan = 0))\n",
    "    right = -tau * tau * np.sum(np.nan_to_num(np.exp(x @ beta + tau * mu) * (-4 * tau * mu * np.exp(x @ beta + tau * mu)\\\n",
    "                                                        + tau * mu * np.exp(2 * x @ beta + 2 * tau * mu)\\\n",
    "                                                        -2 * np.exp(2 * x @ beta + 2 * tau * mu) + tau * mu + 2)\\\n",
    "           /(np.exp(x @ beta + tau * mu) + 1)**4, nan=0))\n",
    "    return left + right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\mu\\tau\\tau}(\\hat\\mu_{i},\\beta)$:\n",
    "\n",
    "$$g_{\\mu\\mu\\tau\\tau}(\\hat\\mu_{i},\\beta) = -2\\sum_{j=1}^{n_i}\\dfrac{\\partial^2\\pi_{ij}}{\\partial\\mu_i\\partial\\tau_i} -\\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial^3\\pi_{ij}}{\\partial\\mu_{i}\\partial\\tau_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_uutt(x, y, mu, beta, tau):\n",
    "    left = -2 * np.sum(np.nan_to_num((np.exp(x @ beta + tau * mu)\\\n",
    "                                  * ((1 - tau * mu) * np.exp(x @ beta + tau * mu) + tau * mu + 1))\\\n",
    "    / (1 + np.exp(x @ beta + tau * mu))**3, nan = 0), axis = 0)\n",
    "    right = -tau * mu * np.sum(np.nan_to_num(np.exp(x @ beta + tau * mu) * (-4 * tau * mu * np.exp(x @ beta + tau * mu)\\\n",
    "                                                        + tau * mu * np.exp(2 * x @ beta + 2 * tau * mu)\\\n",
    "                                                        -2 * np.exp(2 * x @ beta + 2 * tau * mu) + tau * mu + 2)\\\n",
    "           /(np.exp(x @ beta + tau * mu) + 1)**4, nan=0))\n",
    "    return left + right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $g_{\\mu\\mu\\beta\\tau_{i}}(\\hat\\mu_{i},\\beta, \\tau_i)$:\n",
    "\n",
    "$$\n",
    "g_{\\mu\\mu\\beta\\tau}=-\\sum_{j=1}^{n_i}\\dfrac{\\partial^2\\pi_{ij}}{\\partial\\mu_{i}\\partial\\beta} - \\tau_i\\sum_{j=1}^{n_i}\\dfrac{\\partial^3\\pi_{ij}}{\\partial\\mu_{i}\\partial\\beta\\partial\\tau_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_uubt(x, y, mu, beta, tau):\n",
    "    left = -np.sum(-tau * x * np.nan_to_num(np.asarray((np.exp(x @ beta + tau * mu) * (np.exp(x @ beta + tau * mu) - 1)\\\n",
    "                             / (1 + np.exp(x @ beta + tau * mu))**3)), nan = 0), axis = 0)\n",
    "    right = -tau * np.sum(x * np.nan_to_num(np.asarray(np.exp(x @ beta + tau * mu) * (-4 * tau * mu * np.exp(x @ beta + tau * mu)\\\n",
    "                                                             + tau * mu * np.exp(2 * x @ beta + 2 * tau * mu)\\\n",
    "                                                             - np.exp(2 * x @ beta + 2 * tau * mu) + tau * mu + 1)\\\n",
    "                          / (np.exp(x @ beta + tau * mu) + 1)**4), nan = 0), axis = 0)\n",
    "    return left + right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Other derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $\\hat\\omega$:\n",
    "\n",
    "$$\\hat\\omega=\\sqrt{-\\dfrac{1}{g_{\\mu\\mu}(\\hat\\mu_{i}, \\theta)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def omega(x, y, mu, beta, tau):\n",
    "    return np.sqrt(-1/g_uu(x, y, mu, beta, tau))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $\\hat\\mu_\\beta$\n",
    "\n",
    "$$\\hat\\mu_\\beta(\\beta)=-\\dfrac{g_{\\mu\\beta}(\\hat\\mu_{i},\\beta)}{g_{\\mu\\mu}(\\hat\\mu_{i},\\beta)}=\\hat\\omega^2(\\beta)g_{\\mu\\beta}(\\hat\\mu_{i}(\\beta),\\beta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_b(x, y, mu, beta, tau):\n",
    "    return omega(x, y, mu, beta, tau)**2 * g_ub(x, y, mu, beta, tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $\\hat\\mu_{\\beta\\beta'}$:\n",
    "\n",
    "$$\\hat\\mu_{\\beta\\beta'}(\\beta)=\\hat\\omega^2(\\hat\\mu_\\beta\\hat\\mu_{\\beta'} g_{\\mu\\mu\\mu}+\\hat\\mu_{\\beta}g_{\\mu\\mu\\beta'}+\\hat\\mu_{\\beta'}g_{\\mu\\mu\\beta}+g_{\\mu\\beta\\beta'})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_bb(x, y, mu, beta, tau):\n",
    "    result = omega(x, y, mu, beta, tau)**2 * (mu_b(x, y, mu, beta, tau).reshape(x.shape[1],1)\\\n",
    "                                              @ mu_b(x, y, mu, beta, tau).reshape(1,x.shape[1])\\\n",
    "                                              * g_uuu(x, y, mu, beta, tau)\\\n",
    "                                              + 2 * mu_b(x, y, mu, beta, tau).reshape(x.shape[1],1)\\\n",
    "                                              @ g_uub(x, y, mu, beta, tau).reshape(1,x.shape[1])\\\n",
    "                                              + g_ubb(x, y, mu, beta, tau))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $\\hat\\omega_\\beta$:\n",
    "\n",
    "$$\\dfrac{\\partial\\hat\\omega}{\\partial\\beta}=\\dfrac{1}{2}\\hat\\omega^3(g_{\\mu\\mu\\mu}\\hat\\mu_\\beta + g_{\\mu\\mu\\beta})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def omega_b(x, y, mu, beta, tau):\n",
    "    return 0.5 * omega(x, y, mu, beta, tau)**3 * (g_uuu(x, y, mu, beta, tau) * mu_b(x, y, mu, beta, tau)\\\n",
    "                                                    + g_uub(x, y, mu, beta, tau))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $\\hat\\mu_\\tau$\n",
    "\n",
    "$$\\hat\\mu_\\tau(\\tau)=-\\dfrac{g_{\\mu\\tau}(\\hat\\mu_{i},\\tau)}{g_{\\mu\\mu}(\\hat\\mu_{i},\\tau)}=\\hat\\omega^2(\\tau)g_{\\mu\\tau}(\\hat\\mu_{i}(\\tau),\\tau)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_t(x, y, mu, beta, tau):\n",
    "    return omega(x, y, mu, beta, tau)**2 * g_ut(x, y, mu, beta, tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $\\hat\\mu_{\\tau\\tau'}$:\n",
    "\n",
    "$$\\hat\\mu_{\\tau\\tau'}(\\tau)=\\hat\\omega^2(\\hat\\mu_\\tau\\hat\\mu_{\\tau'} g_{\\mu\\mu\\mu}+\\hat\\mu_{\\tau}g_{\\mu\\mu\\tau'}+\\hat\\mu_{\\tau'}g_{\\mu\\mu\\tau}+g_{\\mu\\tau\\tau'})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_tt(x, y, mu, beta, tau):\n",
    "    result = omega(x, y, mu, beta, tau)**2 * (mu_t(x, y, mu, beta, tau)\\\n",
    "                                              * mu_t(x, y, mu, beta, tau)\\\n",
    "                                              * g_uuu(x, y, mu, beta, tau)\\\n",
    "                                              + 2 * mu_t(x, y, mu, beta, tau)\\\n",
    "                                              * g_uut(x, y, mu, beta, tau)\\\n",
    "                                              + g_utt(x, y, mu, beta, tau))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $\\hat\\mu_{\\beta\\tau}$:\n",
    "\n",
    "$$\\hat\\mu_{\\beta\\tau}(\\beta)=\\hat\\omega^2(\\hat\\mu_\\beta\\hat\\mu_{\\tau} g_{\\mu\\mu\\mu}+\\hat\\mu_{\\beta}g_{\\mu\\mu\\tau}+\\hat\\mu_{\\tau}g_{\\mu\\mu\\beta}+g_{\\mu\\beta\\tau})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_bt(x, y, mu, beta, tau):\n",
    "    result = omega(x, y, mu, beta, tau)**2 * (mu_b(x, y, mu, beta, tau)\\\n",
    "                                              * mu_t(x, y, mu, beta, tau)\\\n",
    "                                              * g_uuu(x, y, mu, beta, tau)\\\n",
    "                                              + mu_b(x, y, mu, beta, tau)\\\n",
    "                                              * g_uut(x, y, mu, beta, tau)\\\n",
    "                                              + mu_t(x, y, mu, beta, tau)\\\n",
    "                                              * g_uub(x, y, mu, beta, tau)\\\n",
    "                                              + g_ubt(x, y, mu, beta, tau))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $\\hat\\omega_\\tau$:\n",
    "\n",
    "$$\\dfrac{\\partial\\hat\\omega}{\\partial\\tau}=\\dfrac{1}{2}\\hat\\omega^3(g_{\\mu\\mu\\mu}\\hat\\mu_\\tau + g_{\\mu\\mu\\tau})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def omega_t(x, y, mu, beta, tau):\n",
    "    return 0.5 * omega(x, y, mu, beta, tau)**3 * (g_uuu(x, y, mu, beta, tau) * mu_t(x, y, mu, beta, tau)\\\n",
    "                                                    + g_uut(x, y, mu, beta, tau))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $\\hat\\omega_{\\beta\\beta'}$:\n",
    "\n",
    "$$\\dfrac{\\partial^2}{\\partial\\beta\\partial\\beta'}\\hat\\omega(\\beta)=\\frac{3}{4}\\hat\\omega^5(\\hat\\mu_{\\beta'}g_{\\mu\\mu\\mu}+g_{\\mu\\mu\\beta'})(\\hat\\mu_{\\beta}g_{\\mu\\mu\\mu}+g_{\\mu\\mu\\beta})+\\dfrac{1}{2}\\hat\\omega^3(\\hat\\mu_{\\beta\\beta'}g_{\\mu\\mu\\mu}+\\hat\\mu_\\beta\\hat\\mu_{\\beta'}g_{\\mu\\mu\\mu\\mu}+\\hat\\mu_{\\beta}g_{\\mu\\mu\\mu\\beta'}+\\hat\\mu_{\\beta'}g_{\\mu\\mu\\mu\\beta}+g_{\\mu\\mu\\beta\\beta'})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def omega_bb(x, y, mu, beta, tau):\n",
    "    result = 3/4 * omega(x, y, mu, beta, tau)**5 * (mu_b(x, y, mu, beta, tau) * g_uuu(x, y, mu, beta, tau)\\\n",
    "                                                      + g_uub(x, y, mu, beta, tau)).reshape(x.shape[1],1)\\\n",
    "     @ (mu_b(x, y, mu, beta, tau) * g_uuu(x, y, mu, beta, tau)\\\n",
    "        + g_uub(x, y, mu, beta, tau)).reshape(1,x.shape[1]) + 1/2 * omega(x, y, mu, beta, tau)**3\\\n",
    "     * (mu_bb(x, y, mu, beta, tau) * g_uuu(x, y, mu, beta, tau)\\\n",
    "        + (mu_b(x, y, mu, beta, tau).reshape(x.shape[1],1)\\\n",
    "           @ mu_b(x, y, mu, beta, tau).reshape(1,x.shape[1]) * g_uuuu(x, y, mu, beta, tau))\\\n",
    "        + mu_b(x, y, mu, beta, tau).reshape(x.shape[1],1) @ g_uuub(x, y, mu, beta, tau).reshape(1,x.shape[1])\\\n",
    "        + mu_b(x, y, mu, beta, tau).reshape(x.shape[1],1) @ g_uuub(x, y, mu, beta, tau).reshape(1,x.shape[1])\\\n",
    "        + g_uubb(x, y, mu, beta, tau)\n",
    "       )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def omega_bb(x, y, mu, beta, tau):\n",
    "#     result = 3 / 4 * omega(x, y, mu, beta, tau) ** 5 * (mu_b(x, y, mu, beta, tau) * g_uuu(x, y, mu, beta, tau) \\\n",
    "#                                                           + g_uub(x, y, mu, beta, tau)).reshape(x.shape[1], 1) \\\n",
    "#              @ (mu_b(x, y, mu, beta, tau) * g_uuu(x, y, mu, beta, tau) \\\n",
    "#                 + g_uub(x, y, mu, beta, tau)).reshape(1, x.shape[1]) + 1 / 2 * omega(x, y, mu, beta, tau) ** 3 \\\n",
    "#              * (mu_bb(x, y, mu, beta, tau) * g_uuu(x, y, mu, beta, tau) \\\n",
    "#                 + (mu_b(x, y, mu, beta, tau).reshape(x.shape[1], 1) \\\n",
    "#                    @ mu_b(x, y, mu, beta, tau).reshape(1, x.shape[1]) * g_uuuu(x, y, mu, beta, tau)) \\\n",
    "#                 + mu_b(x, y, mu, beta, tau).reshape(x.shape[1], 1) @ g_uuub(x, y, mu, beta, tau).reshape(1,\n",
    "#                                                                                                              x.shape[\n",
    "#                                                                                                                  1]) \\\n",
    "#                 + mu_bb(x, y, mu, beta, tau)\n",
    "#                 )\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $\\hat\\omega_{\\tau\\tau'}$:\n",
    "\n",
    "$$\\dfrac{\\partial^2}{\\partial\\tau\\partial\\tau'}\\hat\\omega(\\tau)=\\frac{3}{4}\\hat\\omega^5(\\hat\\mu_{\\tau'}g_{\\mu\\mu\\mu}+g_{\\mu\\mu\\tau'})(\\hat\\mu_{\\tau}g_{\\mu\\mu\\mu}+g_{\\mu\\mu\\tau})+\\dfrac{1}{2}\\hat\\omega^3(\\hat\\mu_{\\tau\\tau'}g_{\\mu\\mu\\mu}+\\hat\\mu_\\tau\\hat\\mu_{\\tau'}g_{\\mu\\mu\\mu\\mu}+\\hat\\mu_{\\tau}g_{\\mu\\mu\\mu\\tau'}+\\hat\\mu_{\\tau'}g_{\\mu\\mu\\mu\\tau}+g_{\\mu\\mu\\tau\\tau'})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def omega_tt(x, y, mu, beta, tau):\n",
    "    result = 3/4 * omega(x, y, mu, beta, tau)**5 * (mu_t(x, y, mu, beta, tau) * g_uuu(x, y, mu, beta, tau)\\\n",
    "                                                      + g_uut(x, y, mu, beta, tau))\\\n",
    "     * (mu_t(x, y, mu, beta, tau) * g_uuu(x, y, mu, beta, tau)\\\n",
    "        + g_uut(x, y, mu, beta, tau)) + 1/2 * omega(x, y, mu, beta, tau)**3\\\n",
    "     * (mu_tt(x, y, mu, beta, tau) * g_uuu(x, y, mu, beta, tau)\\\n",
    "        + (mu_t(x, y, mu, beta, tau)\\\n",
    "           * mu_t(x, y, mu, beta, tau) * g_uuuu(x, y, mu, beta, tau))\\\n",
    "        + mu_t(x, y, mu, beta, tau) * g_uuut(x, y, mu, beta, tau)\\\n",
    "        + mu_t(x, y, mu, beta, tau) * g_uuut(x, y, mu, beta, tau)\\\n",
    "        + g_uutt(x, y, mu, beta, tau)\n",
    "       )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $\\hat\\omega_{\\beta\\tau}$:\n",
    "\n",
    "$$\\dfrac{\\partial^2}{\\partial\\beta\\partial\\tau}\\hat\\omega(\\beta)=\\frac{3}{4}\\hat\\omega^5(\\hat\\mu_{\\tau}g_{\\mu\\mu\\mu}+g_{\\mu\\mu\\tau})(\\hat\\mu_{\\beta}g_{\\mu\\mu\\mu}+g_{\\mu\\mu\\beta})+\\dfrac{1}{2}\\hat\\omega^3(\\hat\\mu_{\\beta\\tau}g_{\\mu\\mu\\mu}+\\hat\\mu_\\beta\\hat\\mu_{\\tau}g_{\\mu\\mu\\mu\\mu}+\\hat\\mu_{\\beta}g_{\\mu\\mu\\mu\\tau}+\\hat\\mu_{\\tau}g_{\\mu\\mu\\mu\\beta}+g_{\\mu\\mu\\beta\\tau})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def omega_bt(x, y, mu, beta, tau):\n",
    "    result = 3/4 * omega(x, y, mu, beta, tau)**5 * (mu_t(x, y, mu, beta, tau) * g_uuu(x, y, mu, beta, tau)\\\n",
    "                                                      + g_uut(x, y, mu, beta, tau))\\\n",
    "     * (mu_b(x, y, mu, beta, tau) * g_uuu(x, y, mu, beta, tau)\\\n",
    "        + g_uub(x, y, mu, beta, tau)) + 1/2 * omega(x, y, mu, beta, tau)**3\\\n",
    "     * (mu_bt(x, y, mu, beta, tau) * g_uuu(x, y, mu, beta, tau)\\\n",
    "        + (mu_b(x, y, mu, beta, tau)\\\n",
    "           * mu_t(x, y, mu, beta, tau) * g_uuuu(x, y, mu, beta, tau))\\\n",
    "        + mu_b(x, y, mu, beta, tau) * g_uuut(x, y, mu, beta, tau)\\\n",
    "        + mu_t(x, y, mu, beta, tau) * g_uuub(x, y, mu, beta, tau)\\\n",
    "        + g_uubt(x, y, mu, beta, tau)\n",
    "       )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $\\mathcal l_i'(\\beta)$:\n",
    "\n",
    "$$\\mathcal l_i'(\\beta) = \\dfrac{\\partial\\mathcal l_i}{\\partial\\beta}=\\dfrac{\\hat\\omega_\\beta}{\\hat\\omega}+g_\\mu(\\hat\\mu_{i},\\beta)\\hat\\mu_\\beta(\\beta)+g_\\beta(\\hat\\mu_{i},\\beta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lb_1(x, y, mu, beta, tau):\n",
    "    l1 = omega_b(x, y, mu, beta, tau) / omega(x, y, mu, beta, tau)\\\n",
    "    + g_u(x, y, mu, beta, tau) * mu_b(x, y, mu, beta, tau) + g_b(x, y, mu, beta, tau)\n",
    "    return l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $\\mathcal l_i'(\\tau)$:\n",
    "\n",
    "$$\\mathcal l_i'(\\tau) = \\dfrac{\\partial\\mathcal l_i}{\\partial\\tau}=\\dfrac{\\hat\\omega_\\tau}{\\hat\\omega}+g_\\mu(\\hat\\mu_{i},\\tau)\\hat\\mu_\\tau(\\tau)+g_\\tau(\\hat\\mu_{i},\\tau)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lt_1(x, y, mu, beta, tau):\n",
    "    l1 = omega_t(x, y, mu, beta, tau) / omega(x, y, mu, beta, tau)\\\n",
    "    + g_u(x, y, mu, beta, tau) * mu_t(x, y, mu, beta, tau) + g_t(x, y, mu, beta, tau)\n",
    "    return l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $l''_i(\\beta)$:\n",
    "\n",
    "$$l''_i(\\beta)=\\dfrac{\\partial^2l_i}{\\partial\\beta^2}=\\dfrac{\\hat\\omega_{\\beta\\beta'}\\hat\\omega-\\hat\\omega_\\beta\\hat\\omega_{\\beta'}}{\\hat\\omega^2}+\\hat\\mu_{\\beta\\beta'}g_\\mu+\\hat\\mu_\\beta(\\hat\\mu_{\\beta'}g_{\\mu\\mu}+g_{\\mu\\beta'})+\\hat\\mu_{\\beta'}g_{\\mu\\beta}+g_{\\beta\\beta'}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lb_2(x, y, mu, beta, tau):\n",
    "    l2 = omega(x, y, mu, beta, tau)**(-2) * (omega_bb(x, y, mu, beta, tau) * omega(x, y, mu, beta, tau)\\\n",
    "                                               - omega_b(x, y, mu, beta, tau).reshape(x.shape[1],1)\\\n",
    "                                               @ omega_b(x, y, mu, beta, tau).reshape(1,x.shape[1]))\\\n",
    "     + mu_bb(x, y, mu, beta, tau) * g_u(x, y, mu, beta, tau) + mu_b(x, y, mu, beta, tau).reshape(x.shape[1],1)\\\n",
    "     @ (mu_b(x, y, mu, beta, tau) * g_uu(x, y, mu, beta, tau) + g_ub(x, y, mu, beta, tau)).reshape(1,x.shape[1])\\\n",
    "     + mu_b(x, y, mu, beta, tau).reshape(x.shape[1],1) @ g_ub(x, y, mu, beta, tau).reshape(1,x.shape[1])\\\n",
    "     + g_bb(x, y, mu, beta, tau)\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $l''_i(\\tau)$:\n",
    "\n",
    "$$l''_i(\\tau)=\\dfrac{\\partial^2l_i}{\\partial\\tau^2}=\\dfrac{\\hat\\omega_{\\tau\\tau'}\\hat\\omega-\\hat\\omega_\\tau\\hat\\omega_{\\tau'}}{\\hat\\omega^2}+\\hat\\mu_{\\tau\\tau'}g_\\mu+\\hat\\mu_\\tau(\\hat\\mu_{\\tau'}g_{\\mu\\mu}+g_{\\mu\\tau'})+\\hat\\mu_{\\tau'}g_{\\mu\\tau}+g_{\\tau\\tau'}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lt_2(x, y, mu, beta, tau):\n",
    "    l2 = omega(x, y, mu, beta, tau)**(-2) * (omega_tt(x, y, mu, beta, tau) * omega(x, y, mu, beta, tau)\\\n",
    "                                               - omega_t(x, y, mu, beta, tau)\\\n",
    "                                               * omega_t(x, y, mu, beta, tau))\\\n",
    "     + mu_tt(x, y, mu, beta, tau) * g_u(x, y, mu, beta, tau) + mu_t(x, y, mu, beta, tau)\\\n",
    "     * (mu_t(x, y, mu, beta, tau) * g_uu(x, y, mu, beta, tau) + g_ut(x, y, mu, beta, tau))\\\n",
    "     + mu_t(x, y, mu, beta, tau) * g_ut(x, y, mu, beta, tau)\\\n",
    "     + g_tt(x, y, mu, beta, tau)\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $l''_i(\\beta, \\tau)$:\n",
    "\n",
    "$$l''_i(\\beta)=\\dfrac{\\partial^2l_i}{\\partial\\beta\\partial\\tau_i}=\\dfrac{\\hat\\omega_{\\beta\\tau}\\hat\\omega-\\hat\\omega_\\beta\\hat\\omega_{\\tau}}{\\hat\\omega^2}+\\hat\\mu_{\\beta\\tau}g_\\mu+\\hat\\mu_\\beta(\\hat\\mu_{\\tau}g_{\\mu\\mu}+g_{\\mu\\tau})+\\hat\\mu_{\\tau}g_{\\mu\\beta}+g_{\\beta\\tau}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbt_2(x, y, mu, beta, tau):\n",
    "    l2 = omega(x, y, mu, beta, tau)**(-2) * (omega_bt(x, y, mu, beta, tau) * omega(x, y, mu, beta, tau)\\\n",
    "                                               - omega_b(x, y, mu, beta, tau)\\\n",
    "                                               * omega_t(x, y, mu, beta, tau))\\\n",
    "     + mu_bt(x, y, mu, beta, tau) * g_u(x, y, mu, beta, tau) + mu_b(x, y, mu, beta, tau)\\\n",
    "     * (mu_t(x, y, mu, beta, tau) * g_uu(x, y, mu, beta, tau) + g_ut(x, y, mu, beta, tau))\\\n",
    "     + mu_t(x, y, mu, beta, tau) * g_ub(x, y, mu, beta, tau)\\\n",
    "     + g_bt(x, y, mu, beta, tau)\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for maximizing $\\mu$ with respect to $\\hat\\mu=\\arg\\max_\\mu g(\\mu_{i0};\\beta_0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_mu(x, y, mu, beta, tau, max_iter=100):\n",
    "    for step in range(max_iter):\n",
    "        mu_new = mu - g_u(x, y, mu, beta, tau)/g_uu(x, y, mu, beta, tau)\n",
    "        diff = mu_new - mu\n",
    "        mu = mu_new\n",
    "        if np.abs(diff) < 10**(-10):\n",
    "            break;       \n",
    "    return mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation for $l_i(\\mu, \\beta, \\tau)$:\n",
    "\n",
    "$$l_i(\\mu, \\beta, \\tau) = \\dfrac{1}{2}\\log{(2\\pi)}+\\log(\\hat\\omega)+g(\\hat\\mu_{i},\\beta,\\tau)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l(x, y, mu, beta, tau):\n",
    "    l = 0.5 * np.log(2 * np.pi) + np.log(omega(x, y, mu, beta, tau)) + g(x, y, mu, beta, tau)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace approximation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LA:\n",
    "#     \"\"\"\n",
    "#     A calss to run distributed GLMM\n",
    "\n",
    "#     ...\n",
    "\n",
    "#     Attributes\n",
    "#     ------------\n",
    "#     X : A list of DataFrames\n",
    "#         The data from different sites\n",
    "#     y : A list of arrays\n",
    "#         The binary outcomes from different sites\n",
    "#     beta : An array of params\n",
    "#         Fixed effects coefficents\n",
    "#     lam : Float\n",
    "#         Regularization term\n",
    "#     mu : Float\n",
    "#         The mixed effects coefficients\n",
    "#     tau : Float\n",
    "#         The hyperparameter of the variance of the random efffect\n",
    "\n",
    "#     \"\"\"\n",
    "#     def __init__(self, X, y):        \n",
    "#         # Initialization\n",
    "#         self.p = X[0].shape[1]      # Number of variables\n",
    "#         self.n = len(y)             # Number of sites\n",
    "#         if isinstance(X[0], pd.DataFrame):\n",
    "#             self.var_name = X[0].columns\n",
    "#             self.X = [np.array(data) for data in X]\n",
    "#             self.y = [np.array(outcome).reshape(len(outcome),1) for outcome in y]\n",
    "#         else:\n",
    "#             var_name = []\n",
    "#             for i in range(self.p):\n",
    "#                 var_name += ['X' + str(i+1)]\n",
    "#             self.var_name = var_name\n",
    "#             self.X = X\n",
    "#             self.y = y\n",
    "#         self.beta = np.repeat(0.1, self.p).reshape(self.p, 1)\n",
    "#         self.lam = np.nan\n",
    "#         self.mu = np.repeat(0.01, self.n)\n",
    "#         self.tau = np.repeat(1.0, self.n)\n",
    "#         self.df = pd.DataFrame\n",
    "#         self.score = np.nan\n",
    "#         self.predict = np.nan\n",
    "#         self.time = np.nan\n",
    "        \n",
    "#     def fit(self, lam_it=11, lam_step=1, mu_it=3, beta_it=100, tau_it=20, bt_it=5):\n",
    "#         # Iteration\n",
    "#         pre_score = -10**10\n",
    "#         for self.lam in np.arange(0, lam_it, lam_step):\n",
    "#             start_time = time.time()\n",
    "#             for step_mu in range(mu_it):\n",
    "#                 for i in range(self.n):                    \n",
    "#                     self.mu[i] = max_mu(self.X[i], self.y[i], self.mu[i], self.beta, self.tau[i])\n",
    "#                 print('mu:\\n', self.mu, '\\n')\n",
    "#                 for step_theta in range(bt_it):\n",
    "#                     theta_b = self.beta\n",
    "#                     theta_t = self.tau\n",
    "#                     for step in range(beta_it):\n",
    "#                         lb1 = 0\n",
    "#                         lb2 = 0\n",
    "#                         for i in range(self.n):\n",
    "#                             lb1 += lb_1(self.X[i], self.y[i], self.mu[i], self.beta, self.tau[i])\n",
    "#                             lb2 += lb_2(self.X[i], self.y[i], self.mu[i], self.beta, self.tau[i])\n",
    "#                         lb1 -= (2 * self.lam * self.beta.transpose())[0]\n",
    "#                         lb2 -= np.diag(np.repeat(2 * self.lam, self.p))\n",
    "#                         delta = lb1 @ inv(lb2)\n",
    "#                         new_beta = self.beta - delta.reshape(self.p, 1)\n",
    "#                         if max(np.abs(delta)) < 10 **(-6):\n",
    "#     #                         print('Done with beta iteration')\n",
    "#                             break;\n",
    "#                         if max(np.abs(delta)) > 10 **(3):\n",
    "#     #                         print('Get out of beta iteration (delta > 10^(-3)')\n",
    "#                             break;\n",
    "#                         if True in np.isnan(self.beta):\n",
    "#     #                         print('Error: NaN beta')\n",
    "#                             break;\n",
    "#                         self.beta = new_beta\n",
    "# #                     print('Step ', step + 1, ':\\n')\n",
    "#                     print('Beta:\\n', self.beta, '\\n')\n",
    "# #                     print('Diff:\\n', delta, '\\n')\n",
    "#                     print('Lam:\\n', self.lam, '\\n')\n",
    "# #                     print('Score:\\n',score,'\\n')\n",
    "#                     for step in range(tau_it):\n",
    "#                         for i in range(self.n):\n",
    "#                             lt1 = lt_1(self.X[i], self.y[i], self.mu[i], self.beta, self.tau[i])\n",
    "#                             lt2 = lt_2(self.X[i], self.y[i], self.mu[i], self.beta, self.tau[i])\n",
    "# #                             print('lt1', lt1, '\\n')\n",
    "# #                             print('lt2', lt2, '\\n')\n",
    "#                             delta_tau = lt1/lt2 #- 0.00000001\n",
    "#                             print('delta:', delta_tau, '\\n')\n",
    "#                             new_tau = self.tau[i] - delta_tau\n",
    "                            \n",
    "#                             if np.abs(delta_tau) < 10 **(-5):\n",
    "#                                 self.tau[i] = new_tau\n",
    "#                                 break;\n",
    "#                             if np.abs(delta_tau) > 10 **(2):\n",
    "# #                                 self.tau = np.repeat(1.0, self.n)\n",
    "#                                 break;\n",
    "#                             if True in np.isnan(new_tau):\n",
    "# #                                 self.tau = np.repeat(1.0, self.n)\n",
    "#                                 break;\n",
    "#                             if np.abs(new_tau) < 10**(-5):\n",
    "# #                                 self.tau = np.repeat(1.0, self.n)\n",
    "#                                 break;\n",
    "#                             if new_tau < 0:\n",
    "#                                 break;\n",
    "#                             self.tau[i] = new_tau\n",
    "#                     print('tau:', self.tau)\n",
    "# #                     if (min(np.abs(self.beta - theta_b)) < 10 **(-3)) and (min(np.abs(self.tau - theta_t)) < 10 **(-3)):\n",
    "# #                         break;\n",
    "                   \n",
    "#                 score = 0\n",
    "#                 predict = []\n",
    "#                 for i in range(len(self.X)):\n",
    "#                     score += l(self.X[i], self.y[i], self.mu[i], self.beta, self.tau[i]) - sum(self.lam * (self.beta) **2)\n",
    "#                     predict += [Pi(self.X[i], self.y[i], self.mu[i], self.beta, self.tau[i])]\n",
    "#                 print('Score:\\n',score,'\\n')\n",
    "#                 if True in np.isnan(score):\n",
    "#                     break;\n",
    "#                 if score > pre_score:\n",
    "#                     optimized_beta = self.beta\n",
    "#                     optimized_mu = self.mu\n",
    "#                     optimized_lam = self.lam\n",
    "#                     optimized_tau = self.tau\n",
    "#                     # reset\n",
    "#                     pre_score = score\n",
    "#                     optimized_score = score\n",
    "# #                 self.tau = np.repeat(1.0, self.n)\n",
    "                \n",
    "#         # Returning data\n",
    "#         self.beta = optimized_beta\n",
    "#         self.mu = optimized_mu\n",
    "#         self.lam = optimized_lam\n",
    "#         self.score = optimized_score\n",
    "#         self.predict = np.concatenate(predict)      \n",
    "\n",
    "#         X = np.concatenate(self.X)\n",
    "        \n",
    "#         y = np.concatenate(self.y)\n",
    "\n",
    "#         V = np.diagflat(self.predict * (1 - self.predict))\n",
    "\n",
    "#         SE = np.sqrt(np.diag(inv(np.transpose(X) @ V @ X))).reshape(self.p,1)\n",
    "\n",
    "#         Z = self.beta/SE\n",
    "\n",
    "#         P = 2 * norm.cdf(-1 * np.abs(Z))\n",
    "\n",
    "#         CI_025  = self.beta - 1.959964 * SE\n",
    "#         CI_975  = self.beta + 1.959964 * SE\n",
    "\n",
    "#         self.df = pd.DataFrame({'Coef': np.transpose(self.beta)[0], 'Std.Err': np.transpose(SE)[0],\n",
    "#                            'z': np.transpose(Z)[0], 'P-value': np.transpose(P)[0],\n",
    "#                            '[0.025': np.transpose(CI_025)[0], '0.975]': np.transpose(CI_975)[0]},\n",
    "#                           index = self.var_name)\n",
    "        \n",
    "#         return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LA:\n",
    "    \"\"\"\n",
    "    A calss to run distributed GLMM\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ------------\n",
    "    X : A list of DataFrames\n",
    "        The data from different sites\n",
    "    y : A list of arrays\n",
    "        The binary outcomes from different sites\n",
    "    beta : An array of params\n",
    "        Fixed effects coefficents\n",
    "    lam : Float\n",
    "        Regularization term\n",
    "    mu : Float\n",
    "        The mixed effects coefficients\n",
    "    tau : Float\n",
    "        The hyperparameter of the variance of the random efffect\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):        \n",
    "        # Initialization\n",
    "        self.p = X[0].shape[1]      # Number of variables\n",
    "        self.n = len(y)             # Number of sites\n",
    "        if isinstance(X[0], pd.DataFrame):\n",
    "            self.var_name = X[0].columns\n",
    "            self.X = [np.array(data) for data in X]\n",
    "            self.y = [np.array(outcome).reshape(len(outcome),1) for outcome in y]\n",
    "        else:\n",
    "            var_name = []\n",
    "            for i in range(self.p):\n",
    "                var_name += ['X' + str(i+1)]\n",
    "            self.var_name = var_name\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "        self.beta = np.repeat(0, self.p).reshape(self.p, 1)\n",
    "        self.lam = 0\n",
    "        self.mu = np.repeat(0.5, self.n)\n",
    "        self.tau = 0.5\n",
    "#         self.tau = np.repeat(1.0, self.n)\n",
    "#         self.tau = 0.62909983\n",
    "        self.df = pd.DataFrame\n",
    "        self.score = np.nan\n",
    "        self.predict = np.nan\n",
    "        self.time = np.nan\n",
    "        \n",
    "    def fit(self, lam_it=0, lam_step=1, mu_it=2, theta_it=100):\n",
    "        # Iteration\n",
    "        pre_score = -10**10\n",
    "        for self.lam in np.arange(0, lam_it+lam_step, lam_step):\n",
    "            converge = True\n",
    "            print(f'In lambad = {self.lam}')\n",
    "            for step_mu in range(mu_it):\n",
    "                print(f'The {step_mu+1} step of mu')\n",
    "                self.beta = self.beta.reshape(self.p, 1)\n",
    "                for i in range(self.n):\n",
    "#                     print('mu:\\n', self.mu, '\\n')\n",
    "                    self.mu[i] = max_mu(self.X[i], self.y[i], self.mu[i], self.beta, self.tau)\n",
    "#                 print('mu:\\n', self.mu, '\\n')\n",
    "                for step_theta in range(theta_it):\n",
    "                    theta = np.append(self.beta, self.tau)\n",
    "#                     print('theta:\\n', theta, '\\n')\n",
    "                    lb1 = 0\n",
    "                    lb2 = 0\n",
    "                    lt1 = 0\n",
    "                    lt2 = 0\n",
    "                    lbt2 = 0\n",
    "#                     lt1 = []\n",
    "#                     lt2 = []\n",
    "                    for i in range(self.n):\n",
    "                        lb1 += lb_1(self.X[i], self.y[i], self.mu[i], self.beta, self.tau)\n",
    "                        lb2 += lb_2(self.X[i], self.y[i], self.mu[i], self.beta, self.tau)\n",
    "                        lt1 += lt_1(self.X[i], self.y[i], self.mu[i], self.beta, self.tau)\n",
    "                        lt2 += lt_2(self.X[i], self.y[i], self.mu[i], self.beta, self.tau)\n",
    "                        lbt2 += lbt_2(self.X[i], self.y[i], self.mu[i], self.beta, self.tau)\n",
    "#                         lt1 = np.append(lt1, [lt_1(self.X[i], self.y[i], self.mu[i], self.beta, self.tau[i])])\n",
    "#                         lt2 = np.append(lt2, [lt_2(self.X[i], self.y[i], self.mu[i], self.beta, self.tau[i])])\n",
    "#                     print('diff of tau:\\n',lt1/lt2,'\\n')\n",
    "                    lb1 -= (2 * self.lam * self.beta.transpose())[0]\n",
    "                    lt1 -= 2 * self.lam * self.tau\n",
    "                    lb2 -= np.diag(np.repeat(2 * self.lam, self.p))\n",
    "                    lt2 = np.diag(lt2 - 2 * self.lam)#np.diag(lt2)\n",
    "                    lt2 -= 0.00001\n",
    "                    L1 = np.append(lb1, lt1)\n",
    "#                     L2 = block_diag(lb2, lt2)\n",
    "                    L2 = np.block([\n",
    "                        [lb2, lbt2.reshape(self.p,1)],\n",
    "                        [lbt2.reshape(1,self.p), lt2]\n",
    "                    ])\n",
    "                    delta = L1 @ inv(L2)\n",
    "                    new_theta = theta - delta#.reshape(self.p+self.n, 1)\n",
    "                    if (max(np.abs(delta[:-1])) < 10 **(-2)) and (delta[-1]<10**(-2)):\n",
    "                        self.beta = new_theta[:self.p]\n",
    "                        self.tau = new_theta[self.p:]\n",
    "                        print('Done with iteration')\n",
    "                        break;\n",
    "                    if max(np.abs(delta)) > 10 **(2):\n",
    "                        print('Get out of iteration (delta > 10^(2)')\n",
    "                        break;\n",
    "                    if True in np.isnan(new_theta[:self.p]):\n",
    "                        print('Error: NaN beta, rested to 0')\n",
    "                        # Reset beta and tau\n",
    "                        self.beta = np.repeat(0, self.p).reshape(self.p, 1)\n",
    "                        break;\n",
    "                    if True in np.isnan(new_theta[self.p:]):\n",
    "                        print('Error: NaN tau, rested to 1.0')\n",
    "                        # Reset beta and tau\n",
    "                        self.tau = 1.0\n",
    "                        break;\n",
    "                    if True in np.isnan(self.mu):\n",
    "                        print('Error: NaN mu, rested to 0')\n",
    "                        # Reset beta and tau\n",
    "                        self.mu = np.repeat(0.1, self.n)\n",
    "                        break;                    \n",
    "#                     if new_theta[-1] < 0:\n",
    "# #                         print('Error: negative tau detectived')\n",
    "#                         break;\n",
    "                    self.beta = new_theta[:self.p].reshape(self.p, 1)\n",
    "                    self.tau = new_theta[self.p:]\n",
    "                    if step_theta == theta_it-1:\n",
    "                        print('Error: Did not converged, reset all\\n')\n",
    "                        self.beta = np.repeat(0, self.p).reshape(self.p, 1)\n",
    "                        self.mu = np.repeat(0.1, self.n)\n",
    "                        self.tau = 1.0\n",
    "                        converge = False\n",
    "                        break;\n",
    "#                     print('Step ', step_theta + 1, ':\\n')\n",
    "#                     print('delta:', delta, '\\n')\n",
    "#                     print('Beta:\\n', self.beta, '\\n')\n",
    "#                     print('Diff:\\n', delta, '\\n')\n",
    "#                     print('Lam:\\n', self.lam, '\\n')\n",
    "#                     print('Score:\\n',score,'\\n')\n",
    "#                     print('tau:', self.tau, '\\n')\n",
    "#                     print('mu:\\n', self.mu, '\\n')\n",
    "                if not converge:\n",
    "                    break;\n",
    "#                 else:\n",
    "#                     continue\n",
    "#                 break;\n",
    "                    \n",
    "#                     print('l:\\n',l(self.X[i], self.y[i], self.mu[i], self.beta, self.tau) - sum(self.lam * (self.beta) **2),'\\n')\n",
    "\n",
    "                score = 0\n",
    "                predict = []\n",
    "                self.beta = new_theta[:self.p].reshape(self.p, 1)\n",
    "                for i in range(self.n):\n",
    "    #                     print('Lam:\\n', self.lam, '\\n')\n",
    "    #                     print('tau:', self.tau, '\\n')\n",
    "    #                     print('Beta:\\n', self.beta, '\\n')\n",
    "                    score += l(self.X[i], self.y[i], self.mu[i], self.beta, self.tau) - sum(self.lam * (self.beta) **2)\n",
    "                    predict += [Pi(self.X[i], self.y[i], self.mu[i], self.beta, self.tau)]\n",
    "                print('score:\\n', score, '\\n')\n",
    "                if True in np.isnan(score):\n",
    "                    print('Error: NaN score')\n",
    "                    break;\n",
    "                if (np.mean(score) > pre_score) and converge:\n",
    "                    optimized_beta = self.beta\n",
    "                    optimized_mu = self.mu\n",
    "                    optimized_lam = self.lam\n",
    "                    optimized_tau = self.tau\n",
    "                    # reset\n",
    "                    pre_score = score\n",
    "                    optimized_score = score\n",
    "    #                 self.tau = np.repeat(1.0, self.n)\n",
    "\n",
    "        # Returning data\n",
    "        self.beta = optimized_beta\n",
    "        self.mu = optimized_mu\n",
    "        self.lam = optimized_lam\n",
    "        self.tau = optimized_tau\n",
    "        self.score = optimized_score\n",
    "        self.predict = np.concatenate(predict)      \n",
    "\n",
    "        X = np.concatenate(self.X)\n",
    "        \n",
    "        y = np.concatenate(self.y)\n",
    "\n",
    "        V = np.diagflat(self.predict * (1 - self.predict) + 0.0001)\n",
    "\n",
    "        SE = np.sqrt(np.diag(inv(np.transpose(X) @ V @ X))).reshape(self.p,1)\n",
    "\n",
    "        Z = self.beta/SE\n",
    "\n",
    "        P = 2 * norm.cdf(-1 * np.abs(Z))\n",
    "\n",
    "        CI_025  = self.beta - 1.959964 * SE\n",
    "        CI_975  = self.beta + 1.959964 * SE\n",
    "\n",
    "        self.df = pd.DataFrame({'Coef': np.transpose(self.beta)[0], 'Std.Err': np.transpose(SE)[0],\n",
    "                           'z': np.transpose(Z)[0], 'P-value': np.transpose(P)[0],\n",
    "                           '[0.025': np.transpose(CI_025)[0], '0.975]': np.transpose(CI_975)[0]},\n",
    "                          index = self.var_name)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.array([-1.5,0.1,-0.5,-0.3,0.4,-0.2,-0.25,0.35,-0.1,0.5]).reshape(10, 1)\n",
    "var_name = []\n",
    "for i in range(10):\n",
    "    var_name += ['X' + str(i+1)]\n",
    "df = pd.read_csv('/Users/wli17/Documents/GLMM/Simulation_data_GLMM/Setting_6/2Sites_30PatientsEachSite_LargeVar4_Dataset18.csv', index_col=0)\n",
    "data1 = df[df['Site_ID'] == 1][var_name]\n",
    "data2 = df[df['Site_ID'] == 2][var_name]\n",
    "out1 = np.array(df[df['Site_ID'] == 1]['y']).reshape(30,1)\n",
    "out2 = np.array(df[df['Site_ID'] == 2]['y']).reshape(30,1)\n",
    "data = [data1, data2]\n",
    "out = [out1, out2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.array([-1.5,0.1,-0.5,-0.3,0.4,-0.2,-0.25,0.35,-0.1,0.5]).reshape(10, 1)\n",
    "var_name = []\n",
    "for i in range(10):\n",
    "    var_name += ['X' + str(i+1)]\n",
    "df = pd.read_csv('/Users/wli17/Documents/GLMM/Simulation_data_GLMM/Setting_7/10Sites_30PatientsEachSite_SmallVar1_Dataset18.csv', index_col=0)\n",
    "data = []\n",
    "for k in range(10):\n",
    "    globals()['data%s' % str(k+1)] = np.array(df[df['Site_ID'] == k+1][var_name])\n",
    "    data.append(globals()['data%s' % str(k+1)])\n",
    "out = []\n",
    "for k in range(10):\n",
    "    globals()['out%s' % str(k+1)] = np.array(df[df['Site_ID'] == k+1]['y']).reshape(30,1)\n",
    "    out.append(globals()['out%s' % str(k+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Add_intercept(data):\n",
    "#     for x in data:\n",
    "#         x.insert(loc=0, column='Intercept', value=1)\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = Add_intercept([pd.DataFrame(X1), pd.DataFrame(X2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LA:\n",
    "    \"\"\"\n",
    "    A calss to run distributed GLMM\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ------------\n",
    "    X : A list of DataFrames\n",
    "        The data from different sites\n",
    "    y : A list of arrays\n",
    "        The binary outcomes from different sites\n",
    "    beta : An array of params\n",
    "        Fixed effects coefficents\n",
    "    lam : Float\n",
    "        Regularization term\n",
    "    mu : Float\n",
    "        The mixed effects coefficients\n",
    "    tau : Float\n",
    "        The hyperparameter of the variance of the random efffect\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):        \n",
    "        # Initialization\n",
    "        self.p = X[0].shape[1]      # Number of variables\n",
    "        self.n = len(y)             # Number of sites\n",
    "        if isinstance(X[0], pd.DataFrame):\n",
    "            self.var_name = X[0].columns\n",
    "            self.X = [np.array(data) for data in X]\n",
    "            self.y = [np.array(outcome).reshape(len(outcome),1) for outcome in y]\n",
    "        else:\n",
    "            var_name = []\n",
    "            for i in range(self.p):\n",
    "                var_name += ['X' + str(i+1)]\n",
    "            self.var_name = var_name\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "        self.beta = np.repeat(0.1, self.p).reshape(self.p, 1)\n",
    "        self.lam = 0\n",
    "        self.mu = np.repeat(1, self.n)\n",
    "        self.tau = 1\n",
    "#         self.tau = np.repeat(1.0, self.n)\n",
    "#         self.tau = 0.62909983\n",
    "        self.df = pd.DataFrame\n",
    "        self.score = np.nan\n",
    "        self.predict = np.nan\n",
    "        self.time = np.nan\n",
    "        \n",
    "    def fit(self, lam_it=0, lam_step=1, mu_it=2, theta_it=100):\n",
    "        # Iteration\n",
    "        pre_score = -10**10\n",
    "        for self.lam in np.arange(0, lam_it+lam_step, lam_step):\n",
    "            print(f'In lambad = {self.lam}')\n",
    "            for step_mu in range(mu_it):\n",
    "                print(f'The {step_mu+1} step of mu')\n",
    "                self.beta = self.beta.reshape(self.p, 1)\n",
    "                for i in range(self.n):\n",
    "#                     print('mu:\\n', self.mu, '\\n')\n",
    "                    self.mu[i] = max_mu(self.X[i], self.y[i], self.mu[i], self.beta, self.tau)\n",
    "#                 print('mu:\\n', self.mu, '\\n')\n",
    "                for step_theta in range(theta_it):\n",
    "                    theta = np.append(self.beta, self.tau)\n",
    "#                     print('theta:\\n', theta, '\\n')\n",
    "                    lb1 = 0\n",
    "                    lb2 = 0\n",
    "                    lt1 = 0\n",
    "                    lt2 = 0\n",
    "                    lbt2 = 0\n",
    "#                     lt1 = []\n",
    "#                     lt2 = []\n",
    "                    for i in range(self.n):\n",
    "                        lb1 += lb_1(self.X[i], self.y[i], self.mu[i], self.beta, self.tau)\n",
    "                        lb2 += lb_2(self.X[i], self.y[i], self.mu[i], self.beta, self.tau)\n",
    "                        lt1 += lt_1(self.X[i], self.y[i], self.mu[i], self.beta, self.tau)\n",
    "                        lt2 += lt_2(self.X[i], self.y[i], self.mu[i], self.beta, self.tau)\n",
    "                        lbt2 += lbt_2(self.X[i], self.y[i], self.mu[i], self.beta, self.tau)\n",
    "#                         lt1 = np.append(lt1, [lt_1(self.X[i], self.y[i], self.mu[i], self.beta, self.tau[i])])\n",
    "#                         lt2 = np.append(lt2, [lt_2(self.X[i], self.y[i], self.mu[i], self.beta, self.tau[i])])\n",
    "#                     print('diff of tau:\\n',lt1/lt2,'\\n')\n",
    "                    lb1 -= (2 * self.lam * self.beta.transpose())[0]\n",
    "                    lt1 -= 2 * self.lam * self.tau\n",
    "                    lb2 -= np.diag(np.repeat(2 * self.lam, self.p)) + 0.00001\n",
    "                    lt2 = np.diag(lt2 - 2 * self.lam)#np.diag(lt2)\n",
    "                    lt2 -= 0.00001\n",
    "                    L1 = np.append(lb1, lt1)\n",
    "#                     L2 = block_diag(lb2, lt2)\n",
    "                    L2 = np.block([\n",
    "                        [lb2, lbt2.reshape(self.p,1)],\n",
    "                        [lbt2.reshape(1,self.p), lt2]\n",
    "                    ])\n",
    "                    delta = L1 @ inv(L2)\n",
    "                    new_theta = theta - delta#.reshape(self.p+self.n, 1)\n",
    "                    if (max(np.abs(delta[:-1])) < 10 **(-2)) and (delta[-1]<10**(-2)):\n",
    "                        self.beta = new_theta[:self.p]\n",
    "                        self.tau = new_theta[self.p:]\n",
    "                        converge = True\n",
    "                        print('Done with iteration')\n",
    "                        break;\n",
    "                    if max(np.abs(delta)) > 10 **(2):\n",
    "                        converge = False\n",
    "                        print('Get out of iteration (delta > 10^(2)')\n",
    "                        break;\n",
    "                    if True in np.isnan(new_theta[:self.p]):\n",
    "                        print('Error: NaN beta, rested to 0')\n",
    "                        # Reset beta and tau\n",
    "                        self.beta = np.repeat(0, self.p).reshape(self.p, 1)\n",
    "                        break;\n",
    "                    if True in np.isnan(new_theta[self.p:]):\n",
    "                        print('Error: NaN tau, rested to 1.0')\n",
    "                        # Reset beta and tau\n",
    "                        converge = False\n",
    "                        self.tau = 1.0\n",
    "                        break;\n",
    "                    if True in np.isnan(self.mu):\n",
    "                        print('Error: NaN mu, rested to 0')\n",
    "                        # Reset beta and tau\n",
    "                        converge = False\n",
    "                        self.mu = np.repeat(0.1, self.n)\n",
    "                        break;                    \n",
    "#                     if new_theta[-1] < 0:\n",
    "# #                         print('Error: negative tau detectived')\n",
    "#                         break;\n",
    "                    self.beta = new_theta[:self.p].reshape(self.p, 1)\n",
    "                    self.tau = new_theta[self.p:]\n",
    "                    if step_theta == theta_it-1:\n",
    "                        print('Error: Did not converged, reset all\\n')\n",
    "                        self.beta = np.repeat(0, self.p).reshape(self.p, 1)\n",
    "                        self.mu = np.repeat(1, self.n)\n",
    "                        self.tau = 1\n",
    "                        converge = False\n",
    "                        break;\n",
    "#                     print('Step ', step_theta + 1, ':\\n')\n",
    "#                     print('delta:', delta, '\\n')\n",
    "#                     print('Beta:\\n', self.beta, '\\n')\n",
    "#                     print('Diff:\\n', delta, '\\n')\n",
    "#                     print('Lam:\\n', self.lam, '\\n')\n",
    "#                     print('Score:\\n',score,'\\n')\n",
    "#                     print('tau:', self.tau, '\\n')\n",
    "#                     print('mu:\\n', self.mu, '\\n')\n",
    "#                 if not converge:\n",
    "#                     break;\n",
    "#                 else:\n",
    "#                     continue\n",
    "#                 break;\n",
    "                    \n",
    "#                     print('l:\\n',l(self.X[i], self.y[i], self.mu[i], self.beta, self.tau) - sum(self.lam * (self.beta) **2),'\\n')\n",
    "\n",
    "            score = 0\n",
    "            predict = []\n",
    "            self.beta = new_theta[:self.p].reshape(self.p, 1)\n",
    "            for i in range(self.n):\n",
    "#                     print('Lam:\\n', self.lam, '\\n')\n",
    "#                     print('tau:', self.tau, '\\n')\n",
    "#                     print('Beta:\\n', self.beta, '\\n')\n",
    "                score += l(self.X[i], self.y[i], self.mu[i], self.beta, self.tau) - sum(self.lam * (self.beta) **2)\n",
    "                predict += [Pi(self.X[i], self.y[i], self.mu[i], self.beta, self.tau)]\n",
    "            print('score:\\n', score, '\\n')\n",
    "            if True in np.isnan(score):\n",
    "                print('Error: NaN score')\n",
    "                break;\n",
    "            if (np.mean(score) > pre_score) and converge:\n",
    "                optimized_beta = self.beta\n",
    "                optimized_mu = self.mu\n",
    "                optimized_lam = self.lam\n",
    "                optimized_tau = self.tau\n",
    "                # reset\n",
    "                pre_score = score\n",
    "                optimized_score = score\n",
    "#                 self.tau = np.repeat(1.0, self.n)\n",
    "\n",
    "        # Returning data\n",
    "        optimized_beta[0] = optimized_beta[0] + np.mean(optimized_tau * optimized_mu)\n",
    "        self.beta = optimized_beta\n",
    "        self.mu = optimized_mu\n",
    "        self.lam = optimized_lam\n",
    "        self.tau = optimized_tau\n",
    "        self.score = optimized_score\n",
    "        self.predict = np.concatenate(predict)\n",
    "\n",
    "\n",
    "        X = np.concatenate(self.X)\n",
    "        \n",
    "        y = np.concatenate(self.y)\n",
    "\n",
    "        V = np.diagflat(self.predict * (1 - self.predict) + 0.0001)\n",
    "\n",
    "        SE = np.sqrt(np.diag(inv(np.transpose(X) @ V @ X))).reshape(self.p,1)\n",
    "\n",
    "        Z = self.beta/SE\n",
    "\n",
    "        P = 2 * norm.cdf(-1 * np.abs(Z))\n",
    "\n",
    "        CI_025  = self.beta - 1.959964 * SE\n",
    "        CI_975  = self.beta + 1.959964 * SE\n",
    "\n",
    "        self.df = pd.DataFrame({'Coef': np.transpose(self.beta)[0], 'Std.Err': np.transpose(SE)[0],\n",
    "                           'z': np.transpose(Z)[0], 'P-value': np.transpose(P)[0],\n",
    "                           '[0.025': np.transpose(CI_025)[0], '0.975]': np.transpose(CI_975)[0]},\n",
    "                          index = self.var_name)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In lambad = 0\n",
      "The 1 step of mu\n",
      "Done with iteration\n",
      "The 2 step of mu\n",
      "Error: Did not converged, reset all\n",
      "\n",
      "score:\n",
      " [4.9887165] \n",
      "\n",
      "In lambad = 1\n",
      "The 1 step of mu\n",
      "Get out of iteration (delta > 10^(2)\n",
      "The 2 step of mu\n",
      "Get out of iteration (delta > 10^(2)\n",
      "score:\n",
      " [-116879.03156202] \n",
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'optimized_beta' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-6c70ea2e3840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam_it\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-116-c27c07f5f9f6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lam_it, lam_step, mu_it, theta_it)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Returning data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0moptimized_beta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimized_beta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimized_tau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moptimized_mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimized_beta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimized_mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'optimized_beta' referenced before assignment"
     ]
    }
   ],
   "source": [
    "model=0\n",
    "model = LA(data, out).fit(lam_it=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.tau * model.mu + model.df.Coef[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * norm.cdf(-1 * np.abs(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 10\n",
    "np.random.seed(6)\n",
    "true_beta = (np.random.rand(p,1) - np.random.rand(p,1)) * 10\n",
    "true_tau = np.random.rand(1)\n",
    "true_mu = np.random.rand(2)\n",
    "X1 = (np.random.rand(1000, p) - np.random.rand(1000, p)) * 10\n",
    "p1 = 1 / (1 + np.exp(-(X1 @ true_beta + np.random.normal(true_mu[0], true_tau, 1000).reshape(1000, 1))))\n",
    "y1 = np.random.binomial(1,p1)\n",
    "X2 = (np.random.rand(1000, p) - np.random.rand(1000, p)) * 10\n",
    "p2 = 1 / (1 + np.exp(-(X2 @ true_beta + np.random.normal(true_mu[1], true_tau, 1000).reshape(1000, 1))))\n",
    "y2 = np.random.binomial(1,p2)\n",
    "X = [X1, X2]\n",
    "y = [y1, y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X1).to_csv('/Users/wli17/Documents/GLMM/GLMM/X1_test.csv', header=None, index=None)\n",
    "pd.DataFrame(X2).to_csv('/Users/wli17/Documents/GLMM/GLMM/X2_test.csv', header=None, index=None)\n",
    "pd.DataFrame(y1).to_csv('/Users/wli17/Documents/GLMM/GLMM/y1_test.csv', header=None, index=None)\n",
    "pd.DataFrame(y2).to_csv('/Users/wli17/Documents/GLMM/GLMM/y2_test.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05447451])"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71863724, 0.80217056])"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In lambad = 0\n",
      "The 1 step of mu\n",
      "Done with iteration\n",
      "score:\n",
      " [-0.12868697] \n",
      "\n",
      "The 2 step of mu\n",
      "Get out of iteration (delta > 10^(2)\n",
      "score:\n",
      " [0.95009663] \n",
      "\n",
      "In lambad = 1\n",
      "The 1 step of mu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-619-2ef7078419e0>:4: RuntimeWarning: overflow encountered in power\n",
      "  + 3 * tau**3 * np.exp(2 * x @ beta + 2 * tau * mu) * (np.exp(x @ beta + tau * mu) - 1)/(np.exp(x @ beta + tau * mu) + 1)**4, nan = 0) )\n",
      "<ipython-input-623-2f5f0257cb0a>:6: RuntimeWarning: overflow encountered in power\n",
      "  / (np.exp(x[i] @ beta + tau * mu) + 1)**4, nan=0)\n",
      "<ipython-input-624-a0df8516c7b2>:7: RuntimeWarning: overflow encountered in power\n",
      "  /(np.exp(x @ beta + tau * mu) + 1)**4, nan=0))\n",
      "<ipython-input-625-4c6af2881d57>:8: RuntimeWarning: overflow encountered in power\n",
      "  /(np.exp(x @ beta + tau * mu) + 1)**4, nan=0))\n",
      "<ipython-input-607-e61f74788229>:2: RuntimeWarning: overflow encountered in exp\n",
      "  result = np.nan_to_num(tau * np.asarray((np.exp(x @ beta + tau * mu) /\\\n",
      "<ipython-input-607-e61f74788229>:3: RuntimeWarning: overflow encountered in exp\n",
      "  (1 + np.exp(x @ beta + tau * mu))**2)), nan = 0)\n",
      "<ipython-input-607-e61f74788229>:3: RuntimeWarning: overflow encountered in square\n",
      "  (1 + np.exp(x @ beta + tau * mu))**2)), nan = 0)\n",
      "<ipython-input-607-e61f74788229>:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  result = np.nan_to_num(tau * np.asarray((np.exp(x @ beta + tau * mu) /\\\n",
      "<ipython-input-613-675582d2d9e6>:2: RuntimeWarning: overflow encountered in multiply\n",
      "  return -tau * sum(-tau**2 * np.nan_to_num(np.asarray((np.exp(x @ beta + tau * mu) * (np.exp(x @ beta + tau * mu) - 1)\\\n",
      "<ipython-input-613-675582d2d9e6>:3: RuntimeWarning: overflow encountered in power\n",
      "  / (1 + np.exp(x @ beta + tau * mu))**3)), nan = 0))\n",
      "<ipython-input-615-f845e62daaa7>:5: RuntimeWarning: overflow encountered in multiply\n",
      "  * np.nan_to_num((np.exp(x[i] @ beta + tau * mu) * (np.exp(x[i] @ beta + tau * mu) - 1)\\\n",
      "<ipython-input-615-f845e62daaa7>:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  * np.nan_to_num((np.exp(x[i] @ beta + tau * mu) * (np.exp(x[i] @ beta + tau * mu) - 1)\\\n",
      "<ipython-input-615-f845e62daaa7>:5: RuntimeWarning: overflow encountered in exp\n",
      "  * np.nan_to_num((np.exp(x[i] @ beta + tau * mu) * (np.exp(x[i] @ beta + tau * mu) - 1)\\\n",
      "<ipython-input-615-f845e62daaa7>:6: RuntimeWarning: overflow encountered in exp\n",
      "  / (1 + np.exp(x[i] @ beta + tau * mu))**3), nan = 0))\n",
      "<ipython-input-619-2ef7078419e0>:2: RuntimeWarning: overflow encountered in power\n",
      "  result = -tau * np.sum( np.nan_to_num(-tau**3 * np.exp(2 * x @ beta + 2 * tau * mu)/(np.exp(x @ beta + tau * mu) + 1)**3\\\n",
      "<ipython-input-619-2ef7078419e0>:3: RuntimeWarning: overflow encountered in multiply\n",
      "  - tau**3 * np.exp(x @ beta + tau * mu) * (np.exp(x @ beta + tau * mu) - 1)/(np.exp(x @ beta + tau * mu) + 1)**3\\\n",
      "<ipython-input-619-2ef7078419e0>:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  - tau**3 * np.exp(x @ beta + tau * mu) * (np.exp(x @ beta + tau * mu) - 1)/(np.exp(x @ beta + tau * mu) + 1)**3\\\n",
      "<ipython-input-619-2ef7078419e0>:4: RuntimeWarning: overflow encountered in exp\n",
      "  + 3 * tau**3 * np.exp(2 * x @ beta + 2 * tau * mu) * (np.exp(x @ beta + tau * mu) - 1)/(np.exp(x @ beta + tau * mu) + 1)**4, nan = 0) )\n",
      "<ipython-input-619-2ef7078419e0>:4: RuntimeWarning: overflow encountered in multiply\n",
      "  + 3 * tau**3 * np.exp(2 * x @ beta + 2 * tau * mu) * (np.exp(x @ beta + tau * mu) - 1)/(np.exp(x @ beta + tau * mu) + 1)**4, nan = 0) )\n",
      "<ipython-input-619-2ef7078419e0>:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  + 3 * tau**3 * np.exp(2 * x @ beta + 2 * tau * mu) * (np.exp(x @ beta + tau * mu) - 1)/(np.exp(x @ beta + tau * mu) + 1)**4, nan = 0) )\n",
      "<ipython-input-621-1132f4ee8849>:3: RuntimeWarning: invalid value encountered in add\n",
      "  * (-4 * np.exp(x @ beta + tau * mu) + np.exp(2 * x @ beta + 2 * tau * mu) + 1)\\\n",
      "<ipython-input-623-2f5f0257cb0a>:5: RuntimeWarning: invalid value encountered in add\n",
      "  * (-4 * np.exp(x[i] @ beta + tau * mu) + np.exp(2 * x[i] @ beta + 2 * tau * mu) + 1)\\\n",
      "<ipython-input-608-50a5804aa9b2>:5: RuntimeWarning: overflow encountered in square\n",
      "  * np.nan_to_num((np.exp(x[i] @ beta + tau * mu) / (1 + np.exp(x[i] @ beta + tau * tau * mu))**2), nan = 0))\n",
      "<ipython-input-611-7c5fbbfb1fa9>:4: RuntimeWarning: overflow encountered in square\n",
      "  (1 + np.exp(x @ beta + tau * mu))**2)), nan = 0))\n",
      "<ipython-input-617-603b443ec972>:5: RuntimeWarning: overflow encountered in power\n",
      "  (1 + np.exp(x @ beta + tau * mu))**3, nan = 0) )\n",
      "<ipython-input-624-a0df8516c7b2>:4: RuntimeWarning: invalid value encountered in add\n",
      "  right = -tau * tau * np.sum(np.nan_to_num(np.exp(x @ beta + tau * mu) * (-4 * tau * mu * np.exp(x @ beta + tau * mu)\\\n",
      "<ipython-input-624-a0df8516c7b2>:4: RuntimeWarning: invalid value encountered in subtract\n",
      "  right = -tau * tau * np.sum(np.nan_to_num(np.exp(x @ beta + tau * mu) * (-4 * tau * mu * np.exp(x @ beta + tau * mu)\\\n",
      "<ipython-input-624-a0df8516c7b2>:7: RuntimeWarning: overflow encountered in exp\n",
      "  /(np.exp(x @ beta + tau * mu) + 1)**4, nan=0))\n",
      "<ipython-input-625-4c6af2881d57>:5: RuntimeWarning: invalid value encountered in subtract\n",
      "  right = -tau * mu * np.sum(np.nan_to_num(np.exp(x @ beta + tau * mu) * (-4 * tau * mu * np.exp(x @ beta + tau * mu)\\\n",
      "<ipython-input-625-4c6af2881d57>:8: RuntimeWarning: overflow encountered in exp\n",
      "  /(np.exp(x @ beta + tau * mu) + 1)**4, nan=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get out of iteration (delta > 10^(2)\n",
      "score:\n",
      " [-5468223.80106206] \n",
      "\n",
      "The 2 step of mu\n",
      "Get out of iteration (delta > 10^(2)\n",
      "score:\n",
      " [-inf] \n",
      "\n",
      "In lambad = 2\n",
      "The 1 step of mu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-603-579152624b93>:3: RuntimeWarning: divide by zero encountered in log\n",
      "  + np.nan_to_num(np.log(tau * (np.sqrt(2 * np.pi))**(-1) * np.exp(-mu**2/2)), nan=0)\n",
      "<ipython-input-705-caca051692f4>:152: RuntimeWarning: overflow encountered in add\n",
      "  score += l(self.X[i], self.y[i], self.mu[i], self.beta, self.tau) - sum(self.lam * (self.beta) **2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get out of iteration (delta > 10^(2)\n",
      "score:\n",
      " [-inf] \n",
      "\n",
      "The 2 step of mu\n",
      "Get out of iteration (delta > 10^(2)\n",
      "score:\n",
      " [-inf] \n",
      "\n",
      "In lambad = 3\n",
      "The 1 step of mu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-624-a0df8516c7b2>:6: RuntimeWarning: overflow encountered in multiply\n",
      "  -2 * np.exp(2 * x @ beta + 2 * tau * mu) + tau * mu + 2)\\\n",
      "<ipython-input-625-4c6af2881d57>:7: RuntimeWarning: overflow encountered in multiply\n",
      "  -2 * np.exp(2 * x @ beta + 2 * tau * mu) + tau * mu + 2)\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get out of iteration (delta > 10^(2)\n",
      "score:\n",
      " [-2095641.127512] \n",
      "\n",
      "The 2 step of mu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-603-579152624b93>:3: RuntimeWarning: invalid value encountered in log\n",
      "  + np.nan_to_num(np.log(tau * (np.sqrt(2 * np.pi))**(-1) * np.exp(-mu**2/2)), nan=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get out of iteration (delta > 10^(2)\n",
      "score:\n",
      " [-2962477.85269686] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LA(X, y).fit(lam_it=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95009663])"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "      <th>Std.Err</th>\n",
       "      <th>z</th>\n",
       "      <th>P-value</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>5.304332</td>\n",
       "      <td>0.443454</td>\n",
       "      <td>11.961393</td>\n",
       "      <td>5.660465e-33</td>\n",
       "      <td>4.435177</td>\n",
       "      <td>6.173487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>-4.971702</td>\n",
       "      <td>0.482106</td>\n",
       "      <td>-10.312467</td>\n",
       "      <td>6.189189e-25</td>\n",
       "      <td>-5.916612</td>\n",
       "      <td>-4.026792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>4.181623</td>\n",
       "      <td>0.473420</td>\n",
       "      <td>8.832804</td>\n",
       "      <td>1.020836e-18</td>\n",
       "      <td>3.253738</td>\n",
       "      <td>5.109509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>-6.609150</td>\n",
       "      <td>0.420393</td>\n",
       "      <td>-15.721376</td>\n",
       "      <td>1.079535e-55</td>\n",
       "      <td>-7.433104</td>\n",
       "      <td>-5.785196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5</th>\n",
       "      <td>-5.787121</td>\n",
       "      <td>0.522518</td>\n",
       "      <td>-11.075438</td>\n",
       "      <td>1.650713e-28</td>\n",
       "      <td>-6.811238</td>\n",
       "      <td>-4.763003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6</th>\n",
       "      <td>-4.428618</td>\n",
       "      <td>0.519872</td>\n",
       "      <td>-8.518666</td>\n",
       "      <td>1.614016e-17</td>\n",
       "      <td>-5.447549</td>\n",
       "      <td>-3.409687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X7</th>\n",
       "      <td>-3.209305</td>\n",
       "      <td>0.527538</td>\n",
       "      <td>-6.083557</td>\n",
       "      <td>1.175453e-09</td>\n",
       "      <td>-4.243260</td>\n",
       "      <td>-2.175351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X8</th>\n",
       "      <td>0.347876</td>\n",
       "      <td>0.475340</td>\n",
       "      <td>0.731848</td>\n",
       "      <td>4.642616e-01</td>\n",
       "      <td>-0.583772</td>\n",
       "      <td>1.279524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X9</th>\n",
       "      <td>-6.664182</td>\n",
       "      <td>0.459290</td>\n",
       "      <td>-14.509740</td>\n",
       "      <td>1.051184e-47</td>\n",
       "      <td>-7.564374</td>\n",
       "      <td>-5.763990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X10</th>\n",
       "      <td>-2.015463</td>\n",
       "      <td>0.542240</td>\n",
       "      <td>-3.716923</td>\n",
       "      <td>2.016642e-04</td>\n",
       "      <td>-3.078233</td>\n",
       "      <td>-0.952693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Coef   Std.Err          z       P-value    [0.025    0.975]\n",
       "X1   5.304332  0.443454  11.961393  5.660465e-33  4.435177  6.173487\n",
       "X2  -4.971702  0.482106 -10.312467  6.189189e-25 -5.916612 -4.026792\n",
       "X3   4.181623  0.473420   8.832804  1.020836e-18  3.253738  5.109509\n",
       "X4  -6.609150  0.420393 -15.721376  1.079535e-55 -7.433104 -5.785196\n",
       "X5  -5.787121  0.522518 -11.075438  1.650713e-28 -6.811238 -4.763003\n",
       "X6  -4.428618  0.519872  -8.518666  1.614016e-17 -5.447549 -3.409687\n",
       "X7  -3.209305  0.527538  -6.083557  1.175453e-09 -4.243260 -2.175351\n",
       "X8   0.347876  0.475340   0.731848  4.642616e-01 -0.583772  1.279524\n",
       "X9  -6.664182  0.459290 -14.509740  1.051184e-47 -7.564374 -5.763990\n",
       "X10 -2.015463  0.542240  -3.716923  2.016642e-04 -3.078233 -0.952693"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.16561723, -1.56330664])"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.07909214],\n",
       "       [-1.63387798],\n",
       "       [ 1.44871559],\n",
       "       [-6.0320438 ],\n",
       "       [ 0.2875767 ],\n",
       "       [ 2.56958458],\n",
       "       [ 7.95979736],\n",
       "       [-7.59135789],\n",
       "       [ 3.50513771],\n",
       "       [ 1.6770373 ]])"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.60083512],\n",
       "       [ 0.35633112],\n",
       "       [ 0.13395527],\n",
       "       [-0.10408713],\n",
       "       [-1.34280822],\n",
       "       [ 1.26061877],\n",
       "       [ 0.52601155],\n",
       "       [-0.4624891 ],\n",
       "       [ 0.80183069],\n",
       "       [-0.07703908]])"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85762553])"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((lb_1(LA(X, y).X[1], LA(X, y).y[1], LA(X, y).mu[1], LA(X, y).beta, LA(X, y).tau[1]),\n",
    "np.array(lt1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.49327659],\n",
       "       [4.40395284],\n",
       "       [3.30618879],\n",
       "       [3.12731818],\n",
       "       [3.63733157],\n",
       "       [3.44444707],\n",
       "       [3.42738627],\n",
       "       [3.47021423],\n",
       "       [3.84349734],\n",
       "       [3.66983315]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbt_2(LA(X, y).X[0], LA(X, y).y[0], LA(X, y).mu[0], LA(X, y).beta, LA(X, y).tau).reshape(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt2 = np.append(lt2, [lt_2(LA(X, y).X[1], LA(X, y).y[1], LA(X, y).mu[1], LA(X, y).beta, LA(X, y).tau[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_1(LA(X, y).X[1], LA(X, y).y[1], LA(X, y).mu[1], LA(X, y).beta, LA(X, y).tau[1])/lt_2(LA(X, y).X[1], LA(X, y).y[1], LA(X, y).mu[1], LA(X, y).beta, LA(X, y).tau[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(lt2 - 2*LA(X, y).tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt2 - LA(X, y).tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 0., 0.],\n",
       "       [0., 3., 0.],\n",
       "       [0., 0., 3.]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(3) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
